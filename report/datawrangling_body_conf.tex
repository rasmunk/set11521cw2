\section{Approach}
The user-based collaborative filtering \cite{Schafer2007} approach was selected to make movie recommendation for a set of users. This meant that recommendations for an individual user would be based on what similar users have liked that the current user have not yet rated/seen. This is based on the theory that users with similar taste are likely to provide good recommendations to each other. The key here lies in how is similarity between users determined, in this instance the Pearson correlation coefficient measurement \cite{Wikipedia2017} was selected as the primary method to evaluate similarity, it measures similarity of users by making a linear correlation between what user x and y have rated in terms the score they applied to a set that contains the intersection of movies rated by x and y. The inspiration for this approach was drawn from \cite{Lead} where this was applied in conjunction with a weighted similarity score that makes sure that users you agree most with are rated higher in terms of movie recommendations.

This technology was selected based on multiple factors. This included the suggestions made by \cite{Burke2011} about movie recommendation systems and their domain features including the low risk value of the recommendation, the homogeneous nature of the system and the stability in terms of preference that users have in terms of how much can you rely on previous received information e.g. user's rating history to make future predictions. In terms of technology variation, collaborative filtering provides multiple approaches, e.g. user-based or item based filtering \cite{Yao}. Both of these have merits, the user-based approach increases in computational cost as the number of users increases. The item based however grows whenever new items are added. In this instance the number of users/items is stable since it is not a live system a choice was made to use the user based approach since the dataset contains 671 users and 9125 movies.

\section{Required Knowledge}

The knowledge required for this approach to work include user histories of movie ratings from which user similarity can be based upon. To achieve this a number of public available datasets containing user movie ratings were evaluated. This included the Netflix Prize dataset \cite{bennett0netflix} , the IMDb academic dataset \cite{IMDb2017} and the MovieLens \cite{Harper2015} dataset. From these the MovieLens 100K dataset was chosen as being the most appropriate. The reason for this was that the original Netflix dataset only contained data about when a user rated a movie and not how it was rated. The reason for this was that it was the task for the algorithm to predict the number of reviews and not the actual rating a movie would receive in 2006.  Similar to this the IMDb dataset contained rating of movie's but they weren't tied to any users, meaning that user-based collaborative filtering wasn't feasible. The MovieLens dataset on the other hand doesn't have any of these missing features, meaning that it contained users which had committed at least 20 ratings with a value between 1.0 and 5.0 to different movies. Because of this the MovieLens dataset was selected as the most appropriate to develop this movie recommendation system.

However it was discovered later in the process that there has been developed an altered version of the Netflix dataset which provides actual ratings of movies \cite{Netflix2009}, this was discovered after the MovieLens dataset had been applied.

\section{Algorithm}
	The pseudo code for the similarity and recommendation functions can be seen in Algorithm \ref{alg:simpearsons} and \ref{alg:recommendations}. The similarity function uses Pearson correlation coefficient to determine user similarity on a shared set of movies. The similarity is calculated by basically drawing a line through the rating values of the shared movies. If two users agree on the rating of their shared set of movies the result would be a positive correlation between them, meaning that they are expected to have similar taste. After the similarity has been calculated the recommendation function is run \ref{alg:recommendations}. This function finds movie recommendations for each user by ranking the unseen movies that similar users have seen. The proposed rating for the unseen movies is proportional to how similar the user who has seen is to the current user, i.e. \textit{weighted\_sum[rating.movie\_id] + = [rating.value * similarity]}. After this has been completed for every user the proposed movies are ranked based on their estimated rating.
	
	Upon completion the correlation is stored in the user/user \textit{df\_similarities} matrix and later persisted in the underlying database for later retrieval when a user requests movie recommendations. See \cite{Munk2017} for the full implementation.

	\begin{algorithm}[H]
		\caption{Recommender.sim\_pearsons()}
		\label{alg:simpearsons}
		\begin{algorithmic}
			\STATE $df\_movies\_rated[user] \leftarrow$ Series containing movies rated by user
			\STATE $df\_similarities \leftarrow$ DataFrame consisting of user Id's on the x and y axis
			
			\FORALL{user\_x in users}
				\FORALL{user\_y in users}
					\IF{df\_similarities[user\_x][user\_y] is null \AND user\_x != user\_y}
						\STATE $intersection \leftarrow$ shared movies between user\_x and user\_y
						\IF{$intersection \geq 5$}
							\STATE $x\_ratings \leftarrow$ list of user\_x rating values
							\STATE $y\_ratings \leftarrow$ list of user\_y rating values
							\STATE $pearson \leftarrow personr(x\_ratings, y\_ratings)$
							\STATE $df\_similarities[user\_x][user\_y] \leftarrow pearson$
							\STATE $df\_similarities[user\_y][user\_x] \leftarrow pearson$
						\ENDIF
					\ENDIF
				\ENDFOR
			\ENDFOR
			
			\STATE $Recommender.users\_ratings\_similarities \leftarrow df\_similarities$
		\end{algorithmic}
	\end{algorithm}

	\begin{algorithm}[H]
		\caption{Recommender.recommendations() Page 16 \cite{Lead}}
		\label{alg:recommendations}
		\begin{algorithmic}
			\STATE $weighted\_sum \leftarrow \{\}$
			\STATE $similarity\_sum \leftarrow \{\}$
			\STATE $num\_rows \leftarrow length(users)$
			
			\FORALL{user in users}
				\STATE $df\_similar\_users \leftarrow Recommender.users\_ratings\_similarities[user.id]$
				\STATE $df\_similar\_users \leftarrow $ Remove users that aren't similar.
				\STATE $user\_movies \leftarrow $ user rated movie ids
				\FORALL{target\_user\_id, similarity in df\_similar\_users}
					\IF{$similarity \textgreater 0$}
						\FORALL{rating in users[target\_user\_id].ratings}
							\IF{rating.movie\_id not in user\_movies}
								\STATE $weighted\_sum.setdefault(rating.movie, 0) $
								\STATE $weighted\_sum[rating.movie\_id]\  + =\ (rating.value * similarity)$
								
								\STATE $similarity\_sum.setdefault(rating.movie\_id, 0)$
								\STATE $similarity\_sum[rating.movie_id]\ + =\ similarity$
							\ENDIF
						\ENDFOR
					\ENDIF
				\ENDFOR
			
				\STATE Rank the ratings, users who agree alot with the current user will have their ratings affect the final score the most
				\STATE $rankings \leftarrow [(w\_score / similarity\_sum[movie\_id], movie\_id)$
				\bindent
				    \STATE $for\ movie\_id,\ w\_score\ in\ weighted\_sum.items()]$  
				\eindent
				\STATE $rankings.sort()$
				\STATE $rankings.reverse()$
				\STATE $Recommender.recoms[user] \leftarrow rankings$
			\ENDFOR
		\end{algorithmic}
	\end{algorithm}


\section{Evaluation \& Reflection}

To evaluate whether the recommendations made by the correlation filter was actually usable to the users a series of offline tests were conducted. This included randomly splitting the set of user ratings into a training and testing set in of either 60/40 or 80/20 distribution. This was then used to apply the training dataset to the recommendation engine to evaluate whether the engine would be accurately be able to predict the rating contained in the test data Beyond this the amount of minimum shared rated movies were also varied between either above 0 or equal to and above 5. The hypothesis was that by sharing more movie ratings the algorithm would be able to better predict the missing ratings.

To evaluate the precision of the recommendation predictions the root mean squared error(RMSE) was calculated to determine the accuracy of the predicted ratings. The reason for this was that as described in \cite{Schafer2007} the RMSE emphasizes large errors and penalizes the performance value by how far each individual prediction is from the true value/rating.

The results of the testing can be seen in \ref{table:results}. The results are from running the recommendation test 20 times for each configuration on the MovieLens 100K dataset and extracting the top 100 recommendations. The reason for multiple runs is that because the testing data is a randomly selected sample that by chance could extract a very good set of users. i.e they have rated more movies than the average.

As Table \ref{table:results} shows the mean RMSE improves when the number of required shared movies is increased. T-tests at the 1\% level also shows that there is a significant difference in the results gathered i.e. (p-value = 0,00004) for the 80/20 configurations and (p-value = 4.43e-13) for the 60/40's. However, when looking the percentage between the training/test distributions it indicates no significant difference in the achieved predictions with (p-value = 0.58) between the 60/40 1 or more shared movies vs the 80/20's configuration or (p-value = 0.13) with 60/40 5 or more shared movies vs the 80/20's.

\begin{table}[H]
	\caption{\label{table} Testing Results}
	\centering
	\label{table:results}
	\begin{tabular}{c c c c}
		\hline
		Train \% & Test \% & Shared Movies & Mean RMSE  \\
		\hline
		60 & 40 & 1 or more &  1,58840 \\
		60 & 40 & 5 or more &  1,23029 \\
		80 & 20 & 1 or more &  1,54424 \\
		80 & 20 & 5 or more &  1,29246 \\
		\hline
	\end{tabular}
\end{table} 

Reflecting on these results it shows that in terms of the configuration parameters for the user-based collaborative filtering approach using the Pearson correlation coefficient similarity function the results supports the proposed hypothesis. I.e that an increase in shared movies has a significant impact on the RMSE with a lower prediction average which means that the prediction ability of the system improves. Whether the recommended movies are actually engaging and interesting to the users is another matter and can't be claimed based on these results.

In terms of overall drawbacks of the user-based approach, whenever a user adds a new rating that users recommendations has to be recalculated. This could pose a significant query time whenever a user attempts to retrieve recommendations. To mitigate this the current recommendations are pre-calculated when the system is launched, however this does mean that if a user rates a new item it won't be reflected in the recommendations before the system is relaunched. To counter this in general the item-based approach does seem preferable in that the similarity of each item can be precomputed, hence whenever a user commits a new rating the recommendations can be updated subsequently.